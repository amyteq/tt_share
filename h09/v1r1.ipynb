{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaH100","dataSources":[{"sourceId":118448,"databundleVersionId":14559231,"sourceType":"competition"},{"sourceId":14501829,"sourceType":"datasetVersion","datasetId":9245165},{"sourceId":289055161,"sourceType":"kernelVersion"},{"sourceId":510391,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":404485,"modelId":422384}],"dockerImageVersionId":31260,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%pip uninstall --yes 'keras' 'matplotlib' 'scikit-learn' 'tensorflow'","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-23T08:06:52.904087Z","iopub.execute_input":"2026-01-23T08:06:52.904647Z","iopub.status.idle":"2026-01-23T08:08:09.669569Z","shell.execute_reply.started":"2026-01-23T08:06:52.904630Z","shell.execute_reply":"2026-01-23T08:08:09.669043Z"}},"outputs":[{"name":"stdout","text":"Found existing installation: keras 3.10.0\nUninstalling keras-3.10.0:\n  Successfully uninstalled keras-3.10.0\nFound existing installation: matplotlib 3.10.0\nUninstalling matplotlib-3.10.0:\n  Successfully uninstalled matplotlib-3.10.0\nFound existing installation: scikit-learn 1.6.1\nUninstalling scikit-learn-1.6.1:\n  Successfully uninstalled scikit-learn-1.6.1\nFound existing installation: tensorflow 2.19.0\nUninstalling tensorflow-2.19.0:\n  Successfully uninstalled tensorflow-2.19.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport sys\nimport subprocess\nimport warnings\nwarnings.simplefilter('ignore')\n\ndef set_env(input_archive, temp_dir):\n    if not os.path.exists(temp_dir):\n        os.makedirs(temp_dir, exist_ok=True)\n        subprocess.run(['tar', '-xzf', input_archive, '-C', temp_dir], check=True)\n    \n    subprocess.run([\n        sys.executable, \n        '-m', \n        'pip', \n        'install', \n        '--no-index', \n        '--find-links', \n        f'{temp_dir}/wheels', \n        'unsloth', \n        'trl', \n        'vllm', \n        'openai_harmony'\n    ], \n    stdout=subprocess.DEVNULL,\n    stderr=subprocess.DEVNULL,\n    check=True)\n\nset_env(\n    input_archive='/kaggle/input/aimo-3-utils/wheels.tar.gz', \n    temp_dir='/kaggle/tmp/setup'\n)\n\nsubprocess.run(['ls', '/kaggle/tmp/setup/tiktoken_encodings'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T08:08:09.670573Z","iopub.execute_input":"2026-01-23T08:08:09.670729Z","iopub.status.idle":"2026-01-23T08:12:16.685754Z","shell.execute_reply.started":"2026-01-23T08:08:09.670710Z","shell.execute_reply":"2026-01-23T08:12:16.685372Z"}},"outputs":[{"name":"stdout","text":"cl100k_base.tiktoken\no200k_base.tiktoken\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"CompletedProcess(args=['ls', '/kaggle/tmp/setup/tiktoken_encodings'], returncode=0)"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"os.environ['TRANSFORMERS_NO_TF'] = '1'\nos.environ['TRANSFORMERS_NO_FLAX'] = '1'\nos.environ['CUDA_VISIBLE_DEVICES'] = '0'\nos.environ['TOKENIZERS_PARALLELISM'] = 'false'\nos.environ['TRITON_PTXAS_PATH'] = '/usr/local/cuda/bin/ptxas'\nos.environ['TIKTOKEN_ENCODINGS_BASE'] = '/kaggle/tmp/setup/tiktoken_encodings'\n\nimport gc\nimport re\nimport math\nimport time\nimport queue\nimport threading\nimport contextlib\nfrom collections import deque\nfrom typing import Iterable, Optional\nfrom jupyter_client import KernelManager\nfrom collections import Counter, defaultdict\nfrom concurrent.futures import as_completed, ThreadPoolExecutor\n\nimport pandas as pd\nimport polars as pl\nimport shutil\n\nfrom openai import OpenAI\n\nfrom openai_harmony import (\n    HarmonyEncodingName, \n    load_harmony_encoding, \n    SystemContent, \n    ReasoningEffort, \n    ToolNamespaceConfig, \n    Author, \n    Message, \n    Role, \n    TextContent, \n    Conversation\n)\n\nfrom transformers import set_seed\nimport kaggle_evaluation.aimo_3_inference_server\n\nclass CFG:\n\n    system_prompt = (\n        'You are a world-class International Mathematical Olympiad (IMO) competitor. '\n        'The final answer must be a non-negative integer between 0 and 99999. '\n        'You must place the final integer answer inside \\\\boxed{}.'\n        'Use \\\\boxed{} exactly once at the very end (never for intermediate results).'\n        'If you cannot finish within time, output your best verified result anyway as \\\\boxed{N}.'\n    )\n    \n    tool_prompt = (\n        'Use this tool to execute Python code. '\n        'The environment is a stateful Jupyter notebook. '\n        'You must use print() to output results. '\n\n        # --- preview / slicing safety ---\n        'Preview helper available: use head(x,k) to safely preview dict/list/df. '\n        'Never write something[:k] unless you are sure it is a list/tuple; '\n        'for dict always use list(d.items())[:k] or head(d,k). '\n\n        # --- huge integer safety ---\n        'Do NOT do str(x), len(str(x)), or f\"{x}\" on huge integers. '\n        'Prefer x.bit_length(), x % mod, gcd, or modular arithmetic. '\n        'For large exponents, ALWAYS use pow(a, e, mod); NEVER call pow(a, huge_e) without mod. '\n        'If you need to print a huge integer, use p(x) or pint(x, mod=...) for safe summaries. '\n\n        # --- number theory / correctness ---\n        'When divisors or prime factors matter, use sympy.factorint(n). '\n        'Use explicit namespaces for number theory helpers '\n        '(e.g. math.gcd / math.lcm or sympy.gcd); do NOT use bare gcd/lcm names. '\n\n        # --- performance & safety rules ---\n        'Never use while True; all loops must have explicit bounds. '\n        'Complexity budget: keep each Python call fast (<~2 seconds). '\n        'Start with small bounds and scale up only if needed. '\n        'Avoid large nested loops or wide brute-force scans; '\n        'if a scan is slow, reduce bounds or switch methods '\n        '(e.g. modular arithmetic, factorization, sieving, caching). '\n\n        # --- timeout avoidance ---\n        'Batch work: do NOT call python repeatedly for small steps; '\n        'write one cell that computes all needed values. '\n        'Before any scan or loop, start with a tiny bound (<=200 or <=2000), '\n        'time it, then expand gradually (x2/x3) only if fast. '\n        'If execution times out, do NOT rerun the same code; '\n        'shrink bounds, add caching, or change the algorithm. '\n        'If computing many candidates or ratios, use caching, early-break, '\n        'and avoid list comprehensions that call expensive functions.'\n    )\n\n    preference_prompt = (\n        'You have access to `math`, `numpy` and `sympy` to solve the problem.'\n        'Prefer verifiable approaches: reduce to modular arithmetic / factorization / small candidate sets. '\n        'If an argument depends on choosing the best among many integers, define a candidate set and a coverage strategy (prove a bound or do a bounded scan + verification).'\n    )\n\n    # --- NEW: planner (separate session) ---\n    planner_system_prompt = (\n        'You are an expert IMO problem-solving PLANNER. '\n        'Your job is to produce a short plan to guide another solver. '\n        'Strict rule: do NOT state any computed values for g(c), p, q, or the remainder. '\n        'Do NOT solve the problem. Do NOT output any final answer or \\\\boxed{}. '\n        \"Do NOT include any concluding sentence of the form 'therefore the answer is ...' or 'so remainder is ...'. \"\n        'You may mention problem constants (e.g., 2025, 2025!, M) only as symbols.'\n        'Do NOT write Python code. Output must be concise and actionable.'\n    )\n\n    planner_prompt = (\n        'Output EXACTLY this template, no extra text:\\n'\n        'PLAN:\\n'\n        '- ...\\n'\n        '- ...\\n'\n        '- ...\\n'\n        '- ...\\n'\n        '- ...\\n'\n        'DIGEST:\\n'\n        '- ...\\n'\n        '<<<END>>>\\n'\n        'Rules:\\n'\n        '- PLAN has 5-8 bullets, each <=120 chars.\\n '\n        '- Each PLAN bullet must be an action (verb-first), not a conclusion.\\n '\n        '- DIGEST is exactly 1 bullet, <=256 chars.\\n '\n        '- The line \"<<<END>>>\" must be on its own line (no other text on that line).\\n '\n        '- \"PLAN:\" and \"DIGEST:\" must NOT be prefixed by \"-\" or \"*\". They must be standalone headers.\\n '\n        '- Plan only: do NOT compute the final answer, do NOT include any final numeric result, do NOT write \\\\boxed{}.\\n '\n        '- No explanations, no meta talk, no code.\\n '\n        '- Do NOT include the words: analysis, final, assistant, user, rewrite, template.\\n '    \n        '- Must include at least ONE new verification/search tactic not used in the immediately previous attempt '\n        '(e.g., widen a bound, change enumeration order, add an independent check, prove a missing lemma).\\n'\n        '- Must explicitly list the most recent failure mode (from history) AND one concrete prevention rule '\n        '(imperative form, e.g., \"Do not print huge ints; use bit_length/mod\", \"Do not assume X without a small-case check\").'\n        '- DIGEST must NOT restate PLAN bullets; it should compress the approach into ONE actionable sentence.\\n'\n        '- DIGEST must NOT contain the marker \"<<<END>>>\". The marker line is standalone.\\n'\n    )\n\n    plan_enabled = False\n    digest_enabled = False\n    plan_sanitize = True\n    plan_context_limit = 1536\n    plan_digest_limit = 256\n    plan_max_tokens = 384\n    plan_temperature = 0.2\n\n    warmup_compile_cache = False\n    compile_cache_src = \"/kaggle/input/gpt-oss-120b-cache-compile/torch_compile_cache\"\n    compile_cache_dst = \"/root/.cache/vllm/torch_compile_cache\"\n\n    vllm_port = 8000\n    served_model_name = 'gpt-oss'\n    model_path = '/kaggle/input/gpt-oss-120b/transformers/default/1'\n\n    # not working!! P5 => 62140 ❌\n    # served_model_name = 'gpt-oss-sft'\n    # model_path = '/kaggle/input/gpt-oss-sft-aimo3/transformers/default/1'\n    \n    kv_cache_dtype = 'fp8_e4m3'\n    dtype = 'auto'\n\n    high_problem_timeout = 900\n    base_problem_timeout = 300\n\n    notebook_limit = 17400\n    server_timeout = 180\n\n    session_timeout = 960\n    jupyter_timeout = 7    # 6\n    sandbox_timeout = 3\n\n    stream_interval = 200\n    context_tokens = 65536\n    buffer_tokens = 512\n    search_tokens = 256\n    top_logprobs = 5\n    batch_size = 256\n    early_stop = 4\n    attempts = 8\n    workers = 16\n    turns = 128\n    seed = 42\n\n    gpu_memory_utilization = 0.96\n    temperature = 1.0\n    min_p = 0.02\n\n    select_policy = 'vote'  # 'entropy'\n    penalty_err_enabled = False\n    penalty_err_alpha = 0.1\n\n    # --- NEW: vote bonus for \"verification signal\" ---\n    # none | calls | ok_calls\n    bonus_py_call = \"none\"\n    bonus_py_alpha = 0.05           # 每个(有效)py call 的乘法奖励系数\n    bonus_py_cap = 4                # 最多计入多少个 call（避免奖励刷太多）\n\n    debug = True\n    debug_req = True\n    debug_resp = True\n    debug_limit = 3000\n    debug_cols = ['Log', 'Plan', 'PlanRaw', 'PlanSanitized', 'PlanDigest']\n\ndef _delete(name: str):\n    if name is not None and name != \"\" and name in globals(): del globals()[name]\n\ndef _fmt_time(seconds: float) -> str:\n    s = int(round(max(0.0, seconds)))\n    m, s = divmod(s, 60)\n    return f\"{m}:{s:02d}\"\n\nset_seed(CFG.seed)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T08:12:16.686432Z","iopub.execute_input":"2026-01-23T08:12:16.686584Z","iopub.status.idle":"2026-01-23T08:12:25.042016Z","shell.execute_reply.started":"2026-01-23T08:12:16.686569Z","shell.execute_reply":"2026-01-23T08:12:25.041559Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"class AIMO3Sandbox:\n\n    _port_lock = threading.Lock()\n    _next_port = 50000\n\n    @classmethod\n    def _get_next_ports(cls, count: int = 5) -> list[int]:\n        with cls._port_lock:\n            ports = list(range(cls._next_port, cls._next_port + count))\n            cls._next_port += count\n            return ports\n\n    def __init__(self, timeout: float):\n        self._default_timeout = timeout\n        self._owns_kernel = False\n        self._client = None\n        self._km = None\n        \n        ports = self._get_next_ports(5)\n\n        env = os.environ.copy()\n        env['PYDEVD_DISABLE_FILE_VALIDATION'] = '1'\n        env['PYDEVD_WARN_EVALUATION_TIMEOUT'] = '0'\n        env['JUPYTER_PLATFORM_DIRS'] = '1'\n        env['PYTHONWARNINGS'] = 'ignore'\n        env['MPLBACKEND'] = 'Agg'\n\n        self._km = KernelManager()\n        self._km.shell_port = ports[0]\n        self._km.iopub_port = ports[1]\n        self._km.stdin_port = ports[2]\n        self._km.hb_port = ports[3]\n        self._km.control_port = ports[4]\n        self._km.start_kernel(env=env, extra_arguments=['--Application.log_level=CRITICAL'])\n\n        self._client = self._km.blocking_client()\n        self._client.start_channels()\n        self._client.wait_for_ready(timeout=self._default_timeout)\n        self._owns_kernel = True\n\n        self._helper_imports = \"\"\"\nimport math\nimport numpy\nimport sympy\nimport itertools\nimport collections\nimport mpmath\nimport sys\nimport re\n\nmpmath.mp.dps = 64\n\n# ---- mitigate Python 3.11 huge-int str digit limit if available ----\ntry:\n    if hasattr(sys, \"set_int_max_str_digits\"):\n        sys.set_int_max_str_digits(0)  # unlimited (best-effort)\nexcept Exception:\n    pass\n\"\"\"\n\n        self._helper_methods = \"\"\"\n# ---- safe formatting helpers ----\ndef _safe_int_str(n):\n    try:\n        return str(n)\n    except Exception:\n        try:\n            return f\"<int bit_length={int(n.bit_length())}>\"\n        except Exception:\n            return \"<int>\"\n\ndef _safe_atom(x):\n    if isinstance(x, int):\n        # Avoid huge-int str; represent very large ints compactly\n        bl = x.bit_length()\n        if bl >= 4096:\n            return f\"<int bit_length={bl}>\"\n        return x\n    return x\n\ndef head(x, k=10):\n    \\\"\\\"\\\"Safe preview: works for dict/list/tuple/set/pandas/polars objects.\\\"\\\"\\\"\n    try:\n        if isinstance(x, dict):\n            items = list(x.items())[:k]\n            return [(_safe_atom(a), _safe_atom(b)) for a, b in items]\n        if isinstance(x, (list, tuple)):\n            return [_safe_atom(v) for v in x[:k]]\n        if isinstance(x, set):\n            return [_safe_atom(v) for v in list(x)[:k]]\n        # pandas / polars DataFrame-like\n        if hasattr(x, \"head\"):\n            return x.head(k)\n    except Exception as _e:\n        return f\"<head error: {_e}>\"\n    # fallback: string (safe)\n    try:\n        s = repr(x)\n        return s[:2000] + (\"...\" if len(s) > 2000 else \"\")\n    except Exception:\n        return f\"<{type(x).__name__}>\"\n\ndef pint(x, mod=None, name=None):\n    \\\"\\\"\\\"Safe summary for ints: avoids huge-int str.\\\"\\\"\\\"\n    if not isinstance(x, int):\n        print(f\"{name + ': ' if name else ''}{type(x).__name__}\")\n        return\n    bl = x.bit_length()\n    if mod is None:\n        msg = f\"int(bit_length={bl})\"\n    else:\n        try:\n            msg = f\"int(bit_length={bl}, mod={mod} => {x % mod})\"\n        except Exception:\n            msg = f\"int(bit_length={bl}, mod={mod} => <error>)\"\n    print(f\"{name + ': ' if name else ''}{msg}\")\n\ndef p(x, name=None, k=10):\n    \\\"\\\"\\\"Safe print: dict/list previews via head(); ints via pint(); otherwise repr-trunc.\\\"\\\"\\\"\n    if isinstance(x, int):\n        pint(x, name=name)\n        return\n    if isinstance(x, dict):\n        try:\n            h = head(x, k)\n            print(f\"{name + ': ' if name else ''}dict(len={len(x)}), head={h}\")\n        except Exception as _e:\n            print(f\"{name + ': ' if name else ''}dict(<error: {_e}>)\")\n        return\n    if isinstance(x, (list, tuple, set)):\n        try:\n            h = head(x, k)\n            print(f\"{name + ': ' if name else ''}{type(x).__name__}(len={len(x)}), head={h}\")\n        except Exception as _e:\n            print(f\"{name + ': ' if name else ''}{type(x).__name__}(<error: {_e}>)\")\n        return\n    try:\n        s = repr(x)\n        if len(s) > 2000:\n            s = s[:2000] + \"...\"\n        print(f\"{name + ': ' if name else ''}{s}\")\n    except Exception:\n        print(f\"{name + ': ' if name else ''}<{type(x).__name__}>\")\n\"\"\"\n\n        self.execute([self._helper_imports, self._helper_methods])\n\n    def _format_error(self, traceback: list[str]) -> str:\n        clean_lines = []\n        for frame in traceback:\n            clean_frame = re.sub(r'\\x1b\\[[0-9;]*m', '', frame)\n            if 'File \"' in clean_frame and 'ipython-input' not in clean_frame:\n                continue\n            clean_lines.append(clean_frame)\n        return ''.join(clean_lines)\n\n    def execute(self, code: str | Iterable[str], timeout: float | None = None) -> str:\n        client = self._client\n        effective_timeout = timeout or self._default_timeout\n\n        if isinstance(code, (list, tuple)):\n            code = \"\\n\\n\".join(\n                c.rstrip() for c in code if isinstance(c, str) and c.strip()\n            )\n\n        msg_id = client.execute(\n            code, \n            store_history=True, \n            allow_stdin=False, \n            stop_on_error=False\n        )\n\n        stdout_parts = []\n        stderr_parts = []\n        \n        start_time = time.time()\n\n        while True:\n            elapsed = time.time() - start_time\n\n            if elapsed > effective_timeout:\n                self._km.interrupt_kernel()\n\n                return f'[ERROR] Execution timed out after {effective_timeout} seconds'\n\n            try:\n                msg = client.get_iopub_msg(timeout=1.0)\n\n            except queue.Empty:\n                continue\n\n            if msg.get('parent_header', {}).get('msg_id') != msg_id:\n                continue\n\n            msg_type = msg.get('msg_type')\n            content = msg.get('content', {})\n\n            if msg_type == 'stream':\n                text = content.get('text', '')\n\n                if content.get('name') == 'stdout':\n                    stdout_parts.append(text)\n\n                else:\n                    stderr_parts.append(text)\n\n            elif msg_type == 'error':\n                traceback_list = content.get('traceback', [])\n\n                stderr_parts.append(self._format_error(traceback_list))\n\n            elif msg_type in {'execute_result', 'display_data'}:\n                data = content.get('data', {})\n                text = data.get('text/plain')\n\n                if text:\n                    stdout_parts.append(text if text.endswith('\\n') else f'{text}\\n')\n\n            elif msg_type == 'status':\n                if content.get('execution_state') == 'idle':\n                    break\n\n        stdout = ''.join(stdout_parts)\n        stderr = ''.join(stderr_parts)\n\n        if stderr:\n            return f'{stdout.rstrip()}\\n{stderr}' if stdout else stderr\n\n        return stdout if stdout.strip() else '[WARN] No output. Use print() to see results.'\n\n    def close(self):\n        with contextlib.suppress(Exception):\n            if self._client:\n                self._client.stop_channels()\n\n        if self._owns_kernel and self._km is not None:\n            with contextlib.suppress(Exception):\n                self._km.shutdown_kernel(now=True)\n\n            with contextlib.suppress(Exception):\n                self._km.cleanup_resources()\n\n    def reset(self):\n        self.execute(['%reset -f\\n', self._helper_imports, self._helper_methods])\n\n    def __del__(self):\n        self.close()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T08:12:25.042678Z","iopub.execute_input":"2026-01-23T08:12:25.042957Z","iopub.status.idle":"2026-01-23T08:12:25.056084Z","shell.execute_reply.started":"2026-01-23T08:12:25.042934Z","shell.execute_reply":"2026-01-23T08:12:25.055690Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"class AIMO3Tool:\n\n    def __init__(self, local_jupyter_timeout: float, tool_prompt: str, sandbox=None):\n        self._local_jupyter_timeout = local_jupyter_timeout\n        self._tool_prompt = tool_prompt\n        self._jupyter_session = sandbox\n        \n        self._owns_session = sandbox is None\n        \n        self._execution_lock = threading.Lock()\n        self._init_lock = threading.Lock()\n\n    def _ensure_session(self):\n\n        if self._jupyter_session is None:\n            with self._init_lock:\n                if self._jupyter_session is None:\n                    self._jupyter_session = AIMO3Sandbox(timeout=self._local_jupyter_timeout)\n\n    def _ensure_last_print(self, code: str) -> str:\n\n        lines = code.strip().split('\\n')\n\n        if not lines:\n            return code\n\n        last_line = lines[-1].strip()\n\n        if 'print' in last_line or 'import' in last_line:\n            return code\n\n        if not last_line:\n            return code\n\n        if last_line.startswith('#'):\n            return code\n\n        lines[-1] = 'print(' + last_line + ')'\n\n        return '\\n'.join(lines)\n\n    @property\n    def instruction(self) -> str:\n        return self._tool_prompt\n\n    @property\n    def tool_config(self) -> ToolNamespaceConfig:\n        return ToolNamespaceConfig(\n            name='python', \n            description=self.instruction, \n            tools=[]\n        )\n\n    def _make_response(self, output: str, channel: str | None = None) -> Message:\n        content = TextContent(text=output)\n        author = Author(role=Role.TOOL, name='python')\n        message = Message(author=author, content=[content]).with_recipient('assistant')\n\n        if channel:\n            message = message.with_channel(channel)\n\n        return message\n\n    def process_sync_plus(self, message: Message) -> list[Message]:\n        self._ensure_session()\n        raw_script = message.content[0].text\n        final_script = self._ensure_last_print(raw_script)\n\n        with self._execution_lock:\n            try:\n                output = self._jupyter_session.execute(final_script)\n\n            except TimeoutError as exc:\n                output = f'[ERROR] {exc}'\n\n        return [self._make_response(output, channel=message.channel)]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T08:12:25.057342Z","iopub.execute_input":"2026-01-23T08:12:25.057517Z","iopub.status.idle":"2026-01-23T08:12:25.079780Z","shell.execute_reply.started":"2026-01-23T08:12:25.057502Z","shell.execute_reply":"2026-01-23T08:12:25.079385Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"class AIMO3Logger:\n    def __init__(self, cfg):\n        self.cfg = cfg\n\n    def get_debug_snippet(self, text: str) -> str:\n        limit = self.cfg.debug_limit\n        if not text or len(text) <= limit:\n            return text or \"\"\n        head = text[:100]\n        tail_len = limit - 100\n        tail = text[-tail_len:]\n        return f\"{head}\\n ... \\n{tail}\"\n\n    def format_markdown(self, text: str, mode: str = \"quote\") -> str:\n        if not text:\n            return \"\"\n        lines = text.split('\\n')\n        escaped_lines = [f\"\\\\{line}\" if line.startswith('#') else line for line in lines]\n        processed_text = '\\n'.join(escaped_lines)\n        if mode in [\"markdown\", \"text\", \"python\"]:\n            return f\"```{mode}\\n{processed_text}\\n```\\n\"\n        if mode == \"quote\":\n            return '\\n'.join([f\"> {line}\" for line in escaped_lines]) + \"\\n\"\n        if mode == \"\":\n            return processed_text + \"\\n\"\n        return f\"```\\n{processed_text}\\n```\\n\"\n\n    def log_planner_block(self, plan_raw: str, plan_sanitized: str, plan_digest: str) -> str:\n        raw_snip = self.get_debug_snippet(plan_raw)\n        san_snip = self.get_debug_snippet(plan_sanitized)\n        digest = plan_digest.strip()\n\n        out = []\n        out.append(\"### Planner Output (raw)\\n\")\n        out.append(self.format_markdown(raw_snip, mode=\"text\"))\n        out.append(\"### Planner Output (sanitized)\\n\")\n        out.append(self.format_markdown(san_snip, mode=\"text\"))\n        out.append(\"### Plan Digest\\n\")\n        out.append(self.format_markdown(digest, mode=\"text\"))\n        return \"\".join(out)\n\n    def write_debug_logs(self, detailed_results, vote_dataframe, problem, problem_id=\"UNK\", problem_time=\"\"):\n        if not self.cfg.debug:\n            return\n        try:\n            summary_lines = [\"\\n## Summary Stats\\n\"]\n            if detailed_results:\n                df = pd.DataFrame(detailed_results)\n                cols = [c for c in df.columns if c not in self.cfg.debug_cols]\n                summary_lines.append(df[cols].to_markdown(index=False))\n                summary_lines.append(\"\\n\\n\")\n\n            if not vote_dataframe.empty:\n                summary_lines.append(\"## Vote Counts\\n\")\n                summary_lines.append(vote_dataframe.to_markdown(index=False))\n                summary_lines.append(\"\\n\")\n\n            final_log_content = [f\"# Problem ID: {problem_id}\\n\"]\n            final_log_content.append(f\"Problem spent time: **{problem_time}**\\n\\n\")\n            final_log_content.append(f\"**Problem:**\\n{self.format_markdown(problem)}\\n\")\n            final_log_content.append(f\"**system_prompt:**\\n{self.format_markdown(self.cfg.system_prompt)}\\n\")\n            final_log_content.append(f\"**tool_prompt:**\\n{self.format_markdown(self.cfg.tool_prompt)}\\n\")\n            final_log_content.append(f\"**preference_prompt:**\\n{self.format_markdown(self.cfg.preference_prompt)}\\n\")\n            final_log_content.append(f\"**planner_system_prompt:**\\n{self.format_markdown(self.cfg.planner_system_prompt)}\\n\")\n            final_log_content.append(f\"**planner_prompt:**\\n{self.format_markdown(self.cfg.planner_prompt)}\\n\")\n            final_log_content.append(f\"**plan_enabled**: {self.cfg.plan_enabled}, \"\n                                     f\"**digest_enabled**: {self.cfg.digest_enabled}, \"\n                                     f\"**penalty_err_enabled**: {self.cfg.penalty_err_enabled}, \"\n                                     f\"**penalty_err_alpha**: {self.cfg.penalty_err_alpha}, \"\n                                     f\"**bonus_py_call**: {self.cfg.bonus_py_call}, \"\n                                     f\"**bonus_py_alpha**: {self.cfg.bonus_py_alpha}, \"\n                                     f\"**served_model_name: **{self.cfg.served_model_name}**\\n\")\n            final_log_content.extend(summary_lines)\n            final_log_content.append(\"\\n===\\n\")\n\n            sorted_results = sorted(detailed_results, key=lambda x: x['Attempt'])\n            for res in sorted_results:\n                log_content = res.get('Log', '')\n                if log_content:\n                    final_log_content.append(log_content)\n                    final_log_content.append(\"\\n===\\n\")\n\n            output_path = f\"{problem_id}.md\"\n            with open(output_path, \"w\", encoding=\"utf-8\") as f:\n                f.write(\"\".join(final_log_content))\n            print(f\"Debug log written to {output_path}\")\n        except Exception as e:\n            print(f\"Failed to write debug log: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T08:12:25.080352Z","iopub.execute_input":"2026-01-23T08:12:25.080555Z","iopub.status.idle":"2026-01-23T08:12:25.097786Z","shell.execute_reply.started":"2026-01-23T08:12:25.080536Z","shell.execute_reply":"2026-01-23T08:12:25.097397Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"class AIMO3Server:\n    def __init__(self, cfg, port: int = 8000):\n        self.cfg = cfg\n        self.port = getattr(self.cfg, \"vllm_port\", port)\n        self.base_url = f\"http://localhost:{self.port}/v1\"\n        self.api_key = \"sk-local\"\n        self.client = OpenAI(base_url=self.base_url, api_key=self.api_key, timeout=self.cfg.session_timeout)\n        self.log_file = None\n        \n        self._preload_model_weights()\n        self.process = self._start()\n        self._wait_ready()\n\n    # copy vLLM compile cache if available\n    def _warmup_compile_cache(self):\n        if not getattr(self.cfg, \"warmup_compile_cache\", False):\n            return\n        src = getattr(self.cfg, \"compile_cache_src\", \"\")\n        dst = getattr(self.cfg, \"compile_cache_dst\", \"\")\n        if not src or not dst:\n            return\n        if os.path.exists(src):\n            os.makedirs(os.path.dirname(dst), exist_ok=True)\n            try:\n                shutil.copytree(src, dst, dirs_exist_ok=True)\n            except Exception:\n                pass\n\n    def _preload_model_weights(self) -> None:\n        print(f'Loading model weights from {self.cfg.model_path} into OS Page Cache...')\n        start_time = time.time()\n        \n        files_to_load = []\n        total_size = 0\n    \n        for root, _, files in os.walk(self.cfg.model_path):\n            for file_name in files:\n                file_path = os.path.join(root, file_name)\n    \n                if os.path.isfile(file_path):\n                    files_to_load.append(file_path)\n                    total_size += os.path.getsize(file_path)\n    \n        def _read_file(path: str) -> None:\n            with open(path, 'rb') as file_object:\n                while file_object.read(1024 * 1024 * 1024):\n                    pass\n    \n        with ThreadPoolExecutor(max_workers=self.cfg.workers) as executor:\n            list(executor.map(_read_file, files_to_load))\n    \n        elapsed = time.time() - start_time\n        print(f'Processed {len(files_to_load)} files ({total_size / 1e9:.2f} GB) in {elapsed:.2f} seconds.\\n')\n    \n    def _start(self) -> subprocess.Popen:\n        if self.cfg.warmup_compile_cache:\n            self._warmup_compile_cache()\n\n        cmd = [\n            sys.executable, '-m', 'vllm.entrypoints.openai.api_server', \n            '--seed', str(self.cfg.seed), \n            '--model', self.cfg.model_path, \n            '--served-model-name', self.cfg.served_model_name, \n            '--tensor-parallel-size', '1', \n            '--max-num-seqs', str(self.cfg.batch_size), \n            '--gpu-memory-utilization', str(self.cfg.gpu_memory_utilization), \n            '--host', '0.0.0.0', \n            '--port', str(self.port), \n            '--dtype', self.cfg.dtype, \n            '--kv-cache-dtype', self.cfg.kv_cache_dtype, \n            '--max-model-len', str(self.cfg.context_tokens), \n            '--stream-interval', str(self.cfg.stream_interval), \n            '--async-scheduling', \n            '--disable-log-stats', \n            '--enable-prefix-caching'\n        ]\n    \n        self.log_file = open('vllm_server.log', 'w')\n        return subprocess.Popen(\n            cmd, stdout=self.log_file, stderr=subprocess.STDOUT, start_new_session=True\n        )\n    \n    def _wait_ready(self):\n        print('Waiting for vLLM server...')\n        start_time = time.time()\n    \n        for _ in range(self.cfg.server_timeout):\n            return_code = self.process.poll()\n    \n            if return_code is not None:\n                self.log_file.flush()\n                with open('vllm_server.log', 'r') as log_file:\n                    logs = log_file.read()\n                raise RuntimeError(f'Server died with code {return_code}. Full logs:\\n{logs}\\n')\n    \n            try:\n                self.client.models.list()\n                elapsed = time.time() - start_time\n                print(f'Server is ready (took {elapsed:.2f} seconds).\\n')\n                return\n            except Exception:\n                time.sleep(1)\n        raise RuntimeError('Server failed to start (timeout).\\n')\n\n    def __del__(self):\n        if self.process is not None:\n            with contextlib.suppress(Exception):\n                self.process.terminate()\n                self.process.wait()\n        if self.log_file is not None:\n            with contextlib.suppress(Exception):\n                self.log_file.close()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T08:12:25.098356Z","iopub.execute_input":"2026-01-23T08:12:25.098534Z","iopub.status.idle":"2026-01-23T08:12:25.117225Z","shell.execute_reply.started":"2026-01-23T08:12:25.098516Z","shell.execute_reply":"2026-01-23T08:12:25.116843Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"class AIMO3Planner:\n    \"\"\"\n    Robust planner for Harmony-format models:\n    - Collect token_ids and parse via harmony encoding to avoid 'assistantfinal' artifacts.\n    - Enforce PLAN/DIGEST template with at most one repair.\n    - Never return empty digest; never return non-bullet long paragraphs as plan.\n    \"\"\"\n\n    def __init__(self, cfg, port: int = 8000):\n        self.cfg = cfg\n        self.port = getattr(self.cfg, \"vllm_port\", port)\n        self.base_url = f\"http://localhost:{self.port}/v1\"\n        self.api_key = \"sk-local\"\n        self.client = OpenAI(base_url=self.base_url, api_key=self.api_key, timeout=self.cfg.session_timeout)\n\n        self.encoding = load_harmony_encoding(HarmonyEncodingName.HARMONY_GPT_OSS)\n        self.stop_token_ids = self.encoding.stop_tokens_for_assistant_actions()\n\n    # ----------------- helpers -----------------\n\n    def _build_history_block(self, history: list[dict]) -> str:\n        if not history:\n            return \"ATTEMPT HISTORY: (none)\\n\"\n        keep = getattr(self.cfg, \"planner_history_keep\", 8)\n        maxc = getattr(self.cfg, \"planner_digest_max_chars\", 256)\n        lines = [\"ATTEMPT HISTORY (structured):\"]\n        for r in history[-keep:]:\n            dig = (r.get(\"PlanDigest\") or \"\").replace(\"\\n\", \" \").strip()\n            if len(dig) > maxc:\n                dig = dig[:maxc] + \"...\"\n            lines.append(\n                f\"- Attempt {r.get('Attempt')}: \"\n                f\"Answer={r.get('Answer')}, Entropy={float(r.get('Entropy', 1e9)):.3f}, \"\n                f\"PyCalls={int(r.get('Python Calls', 0) or 0)}, PyErr={int(r.get('Python Errors', 0) or 0)}; \"\n                f\"PlanDigest={dig}\"\n            )\n        return \"\\n\".join(lines) + \"\\n\"\n\n    def _render_prompt_ids(self, system_prompt: str, user_text: str):\n        sys_content = (\n            SystemContent.new()\n            .with_model_identity(system_prompt)\n            .with_reasoning_effort(reasoning_effort=ReasoningEffort.LOW)\n            .with_tools(ToolNamespaceConfig(name=\"none\", description=\"\", tools=[]))\n        )\n        messages = [\n            Message.from_role_and_content(Role.SYSTEM, sys_content),\n            Message.from_role_and_content(Role.USER, user_text),\n        ]\n        conv = Conversation.from_messages(messages)\n        return self.encoding.render_conversation_for_completion(conv, Role.ASSISTANT)\n\n    def _decode_from_token_ids(self, token_ids: list[int]) -> str:\n        if not token_ids:\n            return \"\"\n        msgs = self.encoding.parse_messages_from_completion_tokens(token_ids, Role.ASSISTANT)\n        # concatenate all assistant text contents\n        parts = []\n        for m in msgs:\n            if not m.content:\n                continue\n            for c in m.content:\n                if hasattr(c, \"text\") and c.text:\n                    parts.append(c.text)\n        return \"\".join(parts).strip()\n\n    def _stream_completion(self, system_prompt: str, user_text: str, seed: int, max_tokens: int, temperature: float):\n        prompt_ids = self._render_prompt_ids(system_prompt, user_text)\n        req_timeout = min(30.0, float(self.cfg.session_timeout))\n        try:\n            stream = self.client.completions.create(\n                model=self.cfg.served_model_name,\n                temperature=float(temperature),\n                max_tokens=int(max_tokens),\n                prompt=prompt_ids,\n                seed=int(seed),\n                stream=True,\n                timeout=req_timeout,\n                extra_body={\n                    \"min_p\": self.cfg.min_p,\n                    \"stop_token_ids\": self.stop_token_ids,\n                    \"return_token_ids\": True,\n                },\n            )\n        except Exception as e:\n            # 返回空 planner，让 solver 走 fallback/无 plan 路径\n            return \"\", f\"[PLANNER_STREAM_CREATE_ERROR] {e}\"\n\n        token_buf = []\n        text_buf = []\n        try:\n            for chunk in stream:\n                # token_ids is the reliable path for harmony parsing\n                tids = getattr(chunk.choices[0], \"token_ids\", None)\n                if tids:\n                    token_buf.extend(tids)\n                t = chunk.choices[0].text\n                if t:\n                    text_buf.append(t)\n        finally:\n            stream.close()\n\n        # raw text is only for debugging\n        raw_text = \"\".join(text_buf).strip()\n        parsed_text = self._decode_from_token_ids(token_buf)\n        return parsed_text, raw_text\n\n    def _bulletize(self, text: str, max_lines: int = 8) -> str:\n        t = (text or \"\").strip()\n        if not t:\n            return \"\"\n        lines = [ln.strip() for ln in t.splitlines() if ln.strip()]\n        out = []\n        for ln in lines[:max_lines]:\n            ln = re.sub(r\"^\\s*(analysis|final|commentary)\\s*\", \"\", ln, flags=re.IGNORECASE).strip()\n            if not ln:\n                continue\n            if not ln.startswith((\"-\", \"*\", \"•\")):\n                ln = \"- \" + ln\n            out.append(ln)\n        return \"\\n\".join(out).strip()\n\n    def _strip_answerish_lines(self, plan_part: str) -> str:\n        lines = plan_part.splitlines()\n        bad_kw = (\"\\\\boxed\", \"remainder\", \"mod\", \"final answer\", \"=\", \"so each\", \"therefore\", \"template\", \"assistantfinal\", \"assistant\")\n        out = []\n        for ln in lines:\n            low = ln.lower()\n            # 只过滤“答案型总结句”，保留正常数学等式的可能性会有误伤，但在 planner 场景利大于弊\n            if any(k in low for k in bad_kw) and any(ch.isdigit() for ch in ln):\n                continue\n            out.append(ln)\n        return \"\\n\".join(out).strip()\n\n    def _extract_plan_and_digest(self, text: str) -> tuple[str, str]:\n        \"\"\"\n        Accept headers with optional bullet prefixes:\n          PLAN: or - PLAN:\n          DIGEST: or - DIGEST:\n        \"\"\"\n        t = (text or \"\").strip()\n        if not t:\n            return \"\", \"\"\n\n        # normalize <<<END>>> cut\n        t = re.split(r\"(?m)^\\s*<<<END>>>\\s*$\", t)[0].strip()\n\n        # find headers (allow optional bullet prefix)\n        plan_hdr = re.search(r\"(?im)^\\s*(?:[-*•]\\s*)?PLAN\\s*:\\s*$\", t)\n        dig_hdr = re.search(r\"(?im)^\\s*(?:[-*•]\\s*)?DIGEST\\s*:\\s*$\", t)\n\n        if plan_hdr and dig_hdr and dig_hdr.start() > plan_hdr.end():\n            plan_block = t[plan_hdr.end():dig_hdr.start()].strip()\n            dig_block = t[dig_hdr.end():].strip()\n        else:\n            # fallback: try split by substring if headers are inline\n            if \"DIGEST:\" in t:\n                left, right = t.split(\"DIGEST:\", 1)\n                plan_block = left\n                dig_block = right\n                plan_block = re.sub(r\"(?im)^\\s*(?:[-*•]\\s*)?PLAN\\s*:\\s*\", \"\", plan_block).strip()\n            else:\n                plan_block, dig_block = t, \"\"\n\n        # keep only bullet lines for plan\n        plan_lines = []\n        for ln in plan_block.splitlines():\n            ln = ln.strip()\n            if ln.startswith((\"-\", \"*\", \"•\")):\n                plan_lines.append(ln)\n        plan_part = \"\\n\".join(plan_lines).strip()\n\n        # digest: first bullet line\n        digest_line = \"\"\n        for ln in dig_block.splitlines():\n            ln = ln.strip()\n            if ln.startswith((\"-\", \"*\", \"•\")):\n                digest_line = ln.lstrip(\"-*• \").strip()\n                break\n            \n        plan_part = re.sub(r\"(?i)\\b<<<END>>>\\b\", \"\", plan_part).strip()\n        digest_line = re.sub(r\"(?i)\\s*\\b<<<END>>>\\b\\s*$\", \"\", digest_line).strip()\n\n        return plan_part, digest_line\n\n    def _make_digest_fallback(self, plan_text: str) -> str:\n        maxc = getattr(self.cfg, \"planner_digest_max_chars\", 256)\n        lines = [ln.strip() for ln in (plan_text or \"\").splitlines() if ln.strip()]\n        bullets = [ln.lstrip(\"-*• \").strip() for ln in lines if ln.startswith((\"-\", \"*\", \"•\"))]\n        s = (bullets[0] if bullets else \"\").strip()\n        if not s:\n            s = \"Try a different approach; enforce small scans + modular checks + caching.\"\n        return s[:maxc].strip()\n\n    def _is_good(self, plan_part: str, digest: str) -> bool:\n        if not plan_part:\n            return False\n        nbul = sum(1 for ln in plan_part.splitlines() if ln.strip().startswith((\"-\", \"*\", \"•\")))\n        if nbul < 5:\n            return False\n        return bool(digest.strip())\n\n    # ----------------- main API -----------------\n\n    def gen_plan(self, problem_text: str, history: list[dict], attempt_index: int):\n        # NOTE: planner should be short; do NOT set serial_plan_max_tokens too large.\n        max_tokens = min(int(self.cfg.serial_plan_max_tokens), 512)\n        temp = float(getattr(self.cfg, \"serial_aux_temperature\", 0.7))\n\n        user_prompt = (\n            f\"{self.cfg.planner_prompt}\\n\\n\"\n            f\"PROBLEM:\\n{problem_text}\\n\\n\"\n            f\"{self._build_history_block(history)}\\n\"\n            f\"Output now.\"\n        )\n\n        seed = int((self.cfg.seed + 777) * (attempt_index + 1) ** 2)\n        parsed_text, raw_text = self._stream_completion(\n            system_prompt=self.cfg.planner_system_prompt,\n            user_text=user_prompt,\n            seed=seed,\n            max_tokens=max_tokens,\n            temperature=temp,\n        )\n\n        plan_part, digest = self._extract_plan_and_digest(parsed_text)\n\n        # one repair if bad\n        if not self._is_good(plan_part, digest):\n            repair_user = (\n                \"FORMATTER TASK. Output ONLY the required template.\\n\"\n                \"First line: PLAN:\\n\"\n                \"Then 5-8 lines starting with '- '\\n\"\n                \"Then: DIGEST:\\n\"\n                \"Then exactly one '- ' line (<=256 chars)\\n\"\n                \"Then: <<<END>>>\\n\\n\"\n                f\"PROBLEM:\\n{problem_text}\\n\"\n            )\n            parsed_text2, raw_text2 = self._stream_completion(\n                system_prompt=self.cfg.planner_system_prompt,\n                user_text=repair_user,\n                seed=seed + 1,\n                max_tokens=256,\n                temperature=0.0,\n            )\n            parsed_text = parsed_text2 or parsed_text\n            raw_text = raw_text2 or raw_text\n            plan_part, digest = self._extract_plan_and_digest(parsed_text)\n\n        # plan_part = self._strip_answerish_lines(plan_part)\n        # program-side hard fallback (never return garbage paragraphs)\n        if not plan_part.strip():\n            plan_part = self._bulletize(parsed_text) or self._bulletize(problem_text)\n        if not digest.strip():\n            digest = self._make_digest_fallback(plan_part)\n\n        # truncate plan only (digest stays useful)\n        # plan_part = plan_part[: self.cfg.serial_context_char_limit].strip()\n        # if len(digest) > self.cfg.planner_digest_max_chars:\n        #     digest = digest[: self.cfg.planner_digest_max_chars].strip()\n\n        # return both parsed and raw for logging\n        plan_sanitized = plan_part  # already bullet-only; treat as sanitized\n        plan_raw = raw_text or parsed_text\n        return plan_part, digest, plan_raw, plan_sanitized","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T08:12:25.118032Z","iopub.execute_input":"2026-01-23T08:12:25.118237Z","iopub.status.idle":"2026-01-23T08:12:25.136671Z","shell.execute_reply.started":"2026-01-23T08:12:25.118222Z","shell.execute_reply":"2026-01-23T08:12:25.136310Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"class AIMO3Solver:\n\n    def __init__(self, cfg, port: int = 8000):\n        self.cfg = cfg\n        self.port = getattr(self.cfg, \"vllm_port\", port)\n        self.base_url = f\"http://localhost:{self.port}/v1\"\n        self.api_key = 'sk-local'\n        self.client = OpenAI(base_url=self.base_url, api_key=self.api_key, timeout=self.cfg.session_timeout)\n\n        self.encoding = load_harmony_encoding(HarmonyEncodingName.HARMONY_GPT_OSS)\n        self.stop_token_ids = self.encoding.stop_tokens_for_assistant_actions()\n        \n        self.notebook_start_time = time.time()\n        self.problems_remaining = 50\n        self.logger = AIMO3Logger(cfg)\n        self.planner = AIMO3Planner(cfg)\n        self._initialize_kernels()\n    \n    def _initialize_kernels(self) -> None:\n        print(f'Initializing {self.cfg.workers} persistent Jupyter kernels...')\n        start_time = time.time()\n    \n        self.sandbox_pool = queue.Queue()\n    \n        def _create_sandbox():\n            return AIMO3Sandbox(timeout=self.cfg.jupyter_timeout)\n    \n        with ThreadPoolExecutor(max_workers=self.cfg.workers) as executor:\n            futures = [executor.submit(_create_sandbox) for _ in range(self.cfg.workers)]\n            for future in as_completed(futures):\n                self.sandbox_pool.put(future.result())\n    \n        elapsed = time.time() - start_time\n        print(f'Kernels initialized in {elapsed:.2f} seconds.\\n')\n\n    def _scan_for_answer(self, text: str) -> int | None:\n        pattern = r'\\\\boxed\\s*\\{\\s*([0-9,]+)\\s*\\}'\n        matches = re.findall(pattern, text)\n    \n        if matches:\n            try:\n                clean_value = matches[-1].replace(',', '')\n                value = int(clean_value)\n    \n                if 0 <= value <= 99999:\n                    return value\n    \n            except ValueError:\n                pass\n                \n        pattern = r'final\\s+answer\\s+is\\s*([0-9,]+)'\n        matches = re.findall(pattern, text, re.IGNORECASE)\n    \n        if matches:\n            try:\n                clean_value = matches[-1].replace(',', '')\n                value = int(clean_value)\n    \n                if 0 <= value <= 99999:\n                    return value\n    \n            except ValueError:\n                pass\n    \n        return None\n    \n    def _compute_mean_entropy(self, logprobs_buffer: list) -> float:\n        if not logprobs_buffer:\n            return float('inf')\n    \n        total_entropy = 0.0\n        token_count = 0\n    \n        for top_logprobs_dict in logprobs_buffer:\n            \n            if not isinstance(top_logprobs_dict, dict):\n                continue\n            \n            if not top_logprobs_dict:\n                continue\n            \n            token_entropy = 0.0\n            \n            for token_str, log_prob in top_logprobs_dict.items():\n                prob = math.exp(log_prob)\n                \n                if prob > 0:\n                    token_entropy -= prob * math.log2(prob)\n            \n            total_entropy += token_entropy\n            token_count += 1\n    \n        if token_count == 0:\n            return float('inf')\n    \n        return total_entropy / token_count\n\n    def _process_attempt(\n        self, \n        problem: str, \n        system_prompt: str, \n        attempt_index: int, \n        stop_event: threading.Event, \n        deadline: float,\n        problem_id: str,\n        plan: str = \"\",\n        plan_digest: str = \"\",\n        plan_raw: str = \"\",\n        plan_sanitized: str = \"\",\n    ) -> dict:\n        attempt_log = deque([])\n        attempt_start = time.time()\n\n        if stop_event.is_set() or time.time() > deadline:\n            print(f\"Problem: {problem_id} TIMEOUT!\")\n            return {\n                'Attempt': attempt_index + 1, \n                'Answer': None, \n                'Python Calls': 0, \n                'Python Errors': 0, \n                'Response Length': 0, \n                'Entropy': float('inf'),\n                'Log': \"\\n\".join(attempt_log)\n            }\n    \n        local_tool = None\n        sandbox = None\n        python_calls = 0\n        python_errors = 0\n        total_tokens = 0\n        final_answer = None\n        \n        logprobs_buffer = []\n        attempt_seed = int(math.pow(self.cfg.seed + attempt_index, 2))\n    \n        try:\n            sandbox = self.sandbox_pool.get(timeout=self.cfg.sandbox_timeout)\n            local_tool = AIMO3Tool(\n                local_jupyter_timeout=self.cfg.jupyter_timeout, \n                tool_prompt=self.cfg.tool_prompt, \n                sandbox=sandbox\n            )\n            encoding = self.encoding\n\n            aug = \"\"\n            if plan:\n                aug += f\"\\n\\n=== CURRENT ATTEMPT PLAN ===\\n{plan}\\n\"\n            if aug:\n                aug += \"\\nFollow the plan.\\n\"\n            full_problem = problem + aug\n            if self.cfg.debug and self.logger:\n                attempt_log.append(self.logger.log_planner_block(plan_raw, plan_sanitized, plan_digest))\n                attempt_log.append(\"### Planner Augmentation\\n\")\n                attempt_log.append(f\"{self.logger.format_markdown(aug, mode='text')}\\n\")\n\n            sys_content = (\n                SystemContent.new()\n                .with_model_identity(system_prompt)\n                .with_reasoning_effort(reasoning_effort=ReasoningEffort.HIGH)\n                .with_tools(local_tool.tool_config)\n            )\n            messages = [\n                Message.from_role_and_content(Role.SYSTEM, sys_content),\n                Message.from_role_and_content(Role.USER, full_problem), # problem\n            ]\n            conversation = Conversation.from_messages(messages)\n\n            for turn_i in range(self.cfg.turns):\n                if stop_event.is_set() or time.time() > deadline:\n                    break\n    \n                prompt_ids = encoding.render_conversation_for_completion(conversation, Role.ASSISTANT)\n                max_tokens = self.cfg.context_tokens - len(prompt_ids)\n    \n                if max_tokens < self.cfg.buffer_tokens:\n                    break\n\n                if self.cfg.debug and self.cfg.debug_req:\n                    # convert prompt_ids (tensors) back to readable text\n                    # which includes LLM special symbols like <|im_start|>\n                    full_request_text = encoding.decode(prompt_ids)\n                    \n                    snippet = self.logger.get_debug_snippet(full_request_text)\n                    formatted_req = self.logger.format_markdown(snippet)\n                    attempt_log.append(f\"### Turn {turn_i} - Raw Request to Model:\")\n                    attempt_log.append(formatted_req)\n\n                try:\n                    req_timeout = max(1.0, deadline - time.time())\n                    stream = self.client.completions.create(\n                        model=self.cfg.served_model_name, \n                        temperature=self.cfg.temperature, \n                        logprobs=self.cfg.top_logprobs, \n                        max_tokens=max_tokens, \n                        prompt=prompt_ids, \n                        seed=attempt_seed, \n                        stream=True, \n                        timeout=req_timeout,\n                        extra_body={\n                            'min_p': self.cfg.min_p, \n                            'stop_token_ids': self.stop_token_ids, \n                            'return_token_ids': True\n                        },\n                    )\n                except Exception as e:\n                    # stream create failed -> don't hang; record & break this attempt turn\n                    if self.cfg.debug:\n                        attempt_log.append(\n                            f\"### Turn {turn_i} - Stream Create Failed (timeout={req_timeout:.1f}s)\\n\"\n                            f\"{self.logger.format_markdown(str(e), mode='text')}\\n\"\n                        )\n                    break\n\n                full_response_text = \"\"\n                try:\n                    token_buffer = []\n                    text_chunks = []\n    \n                    for chunk in stream:\n                        if stop_event.is_set() or time.time() > deadline:\n                            break\n    \n                        new_tokens = chunk.choices[0].token_ids\n                        new_text = chunk.choices[0].text\n    \n                        if new_tokens:\n                            token_buffer.extend(new_tokens)\n                            total_tokens += len(new_tokens)\n                            text_chunks.append(new_text)\n                            if self.cfg.debug and self.cfg.debug_resp:\n                                full_response_text += new_text\n\n                            chunk_logprobs = chunk.choices[0].logprobs\n                            if chunk_logprobs is not None:\n                                if chunk_logprobs.top_logprobs:\n                                    logprobs_buffer.extend(chunk_logprobs.top_logprobs)\n    \n                        if '}' in new_text:\n                            search_text = ''.join(text_chunks[-self.cfg.search_tokens:])\n                            answer = self._scan_for_answer(search_text)\n    \n                            if answer is not None:\n                                final_answer = answer\n                                break\n    \n                finally:\n                    stream.close()\n\n                if self.cfg.debug and full_response_text:\n                    attempt_log.append(f\"### Turn {turn_i} - Model Response:\")\n                    formatted_resp = self.logger.format_markdown(full_response_text)\n                    attempt_log.append(formatted_resp)\n\n                if final_answer is not None:\n                    break\n    \n                if not token_buffer:\n                    break\n    \n                new_messages = encoding.parse_messages_from_completion_tokens(token_buffer, Role.ASSISTANT)\n                conversation.messages.extend(new_messages)\n                last_message = new_messages[-1]\n    \n                if last_message.channel == 'final':\n                    answer_text = last_message.content[0].text\n                    final_answer = self._scan_for_answer(answer_text)\n                    break\n    \n                if last_message.recipient == 'python':\n                    python_calls += 1\n                    tool_responses = local_tool.process_sync_plus(last_message)\n                    response_text = tool_responses[0].content[0].text\n\n                    if self.cfg.debug:\n                        code_content = last_message.content[0].text\n                        attempt_log.append(f\"### Turn {turn_i} - Python Call:\")\n                        attempt_log.append(f\"```python\\n{code_content}\\n```\\n\")\n\n                        attempt_log.append(f\"### Turn {turn_i} - Python Output:\")\n                        snippet_out = self.logger.get_debug_snippet(response_text)\n                        formatted_out = self.logger.format_markdown(snippet_out, mode=\"text\")\n                        attempt_log.append(f\"{formatted_out}\\n\")\n\n                    if response_text.startswith('[ERROR]') or 'Traceback' in response_text or 'Error:' in response_text:\n                        python_errors += 1\n    \n                    conversation.messages.extend(tool_responses)\n    \n        except Exception as exc:\n            python_errors += 1\n            if self.cfg.debug:\n                attempt_log.append(f\"\\n**EXCEPTION:** {str(exc)}\\n\")\n\n        finally:\n            if sandbox is not None:\n                sandbox.reset()\n                self.sandbox_pool.put(sandbox)\n    \n        mean_entropy = self._compute_mean_entropy(logprobs_buffer)\n        attempt_elapsed = time.time() - attempt_start\n        attempt_time = _fmt_time(attempt_elapsed)\n        if self.cfg.debug:\n            attempt_log.appendleft(f\"Attempt spent time: **{attempt_time}**\\n\")\n            attempt_log.appendleft(f\"## Attempt {attempt_index + 1}\\n\")\n    \n        return {\n            'Attempt': attempt_index + 1, \n            'Response Length': total_tokens, \n            'Python Calls': python_calls, \n            'Python Errors': python_errors, \n            'Entropy': mean_entropy, \n            'Answer': final_answer,\n            'Plan': plan,\n            'PlanDigest': plan_digest,\n            'PlanRaw': plan_raw,\n            'PlanSanitized': plan_sanitized,\n            'Log': \"\\n\".join(attempt_log),\n            'Time': attempt_time\n        }\n    \n    def _select_answer_by_vote(self, detailed_results: list) -> tuple[pd.DataFrame, int]:\n        stats = defaultdict(lambda: {'votes': 0, 'calls': 0})\n        for result in detailed_results:\n            answer = result['Answer']\n\n            if answer is not None:\n                stats[answer]['votes'] += 1\n                stats[answer]['calls'] += result['Python Calls']\n\n        sorted_stats = sorted(\n            stats.items(), \n            key=lambda item: (item[1]['votes'], item[1]['calls']), \n            reverse=True\n        )\n\n        vote_data = []\n\n        for answer, data in sorted_stats:\n            vote_data.append((answer, data['votes'], data['calls']))\n\n        vote_dataframe = pd.DataFrame(vote_data, columns=['Answer', 'Votes', 'Calls'])\n        display(vote_dataframe)\n\n        final_answer = sorted_stats[0][0]\n        final_votes = sorted_stats[0][1]['votes']\n        final_calls = sorted_stats[0][1]['calls']\n\n        print(f'\\nFinal Result: {final_answer} | Votes: {final_votes} | Calls: {final_calls}\\n')\n        return vote_dataframe, final_answer\n\n    def _calc_score(self, result) -> float:\n        entropy = result['Entropy']\n        py_calls = int(result.get('Python Calls', 0) or 0)\n        py_errs = int(result.get('Python Errors', 0) or 0)\n        score = 1.0 / max(entropy, 1e-9)\n\n        penalty_err_enabled = getattr(self.cfg, \"penalty_err_enabled\", False)\n        penalty_err_alpha = float(getattr(self.cfg, \"penalty_err_alpha\", 0.05))\n        if penalty_err_enabled and penalty_err_alpha > 0:\n            score *= 1.0 / (1.0 + self.cfg.penalty_err_alpha * py_errs)\n    \n        mode = getattr(self.cfg, \"vote_py_bonus_mode\", \"none\")\n        if mode and mode != \"none\":\n            if mode == \"calls\":\n                sig = py_calls\n            elif mode == \"ok_calls\":\n                sig = max(0, py_calls - py_errs)\n            else:\n                sig = 0\n\n            cap = int(getattr(self.cfg, \"vote_py_bonus_cap\", 4))\n            alpha = float(getattr(self.cfg, \"vote_py_bonus_alpha\", 0.05))\n            sig = min(sig, cap)\n            score *= (1.0 + alpha * sig)\n        return score\n\n    def _select_answer_by_score(self, detailed_results: list) -> tuple[pd.DataFrame, int]:\n        answer_score = defaultdict(float)\n        answer_votes = defaultdict(int)\n\n        for result in detailed_results:\n            answer = result['Answer']\n            \n            if answer is not None:\n                score = self._calc_score(result)\n                answer_score[answer] += score\n                answer_votes[answer] += 1\n\n        scored_answers = []\n\n        for answer, total_score in answer_score.items():\n            scored_answers.append({\n                'answer': answer, \n                'votes': answer_votes[answer], \n                'score': total_score\n            })\n\n        scored_answers.sort(key=lambda x: x['score'], reverse=True)\n\n        vote_data = []\n\n        for item in scored_answers:\n            vote_data.append((\n                item['answer'], \n                item['votes'], \n                item['score']\n            ))\n\n        vote_dataframe = pd.DataFrame(\n            vote_data, \n            columns=['Answer', 'Votes', 'Score']\n        )\n\n        vote_dataframe = vote_dataframe.round({'Score': 3})\n        display(vote_dataframe)\n        \n        if not scored_answers:\n            print('\\nFinal Answer: 0\\n')\n            return vote_dataframe, 0\n\n        final_answer = scored_answers[0]['answer']    \n        print(f'\\nFinal Answer: {final_answer}\\n')\n        return vote_dataframe, final_answer\n\n    def _select_answer(self, detailed_results: list) -> tuple[pd.DataFrame, int]:\n        if self.cfg.select_policy == 'vote':\n            return self._select_answer_by_vote(detailed_results)\n        else:\n            return self._select_answer_by_score(detailed_results)\n\n    def solve_problem(self, problem: str, problem_id: str = \"UNK\") -> int:\n        print(f'\\nProblem: {problem}\\n')\n        problem_start = time.time()\n        \n        user_input = f'{problem} {self.cfg.preference_prompt}'\n    \n        elapsed_global = time.time() - self.notebook_start_time\n        time_left = self.cfg.notebook_limit - elapsed_global\n        problems_left_others = max(0, self.problems_remaining - 1)\n        reserved_time = problems_left_others * self.cfg.base_problem_timeout\n    \n        budget = time_left - reserved_time\n        budget = min(budget, self.cfg.high_problem_timeout)\n        budget = max(budget, self.cfg.base_problem_timeout)\n    \n        deadline = time.time() + budget\n    \n        print(f'Budget: {budget:.2f} seconds | Deadline: {deadline:.2f}\\n')\n    \n        tasks = []\n    \n        for attempt_index in range(self.cfg.attempts):\n            tasks.append((self.cfg.system_prompt, attempt_index))\n    \n        detailed_results = []\n        valid_answers = []\n        stop_event = threading.Event()\n        executor = ThreadPoolExecutor(max_workers=self.cfg.workers)\n    \n        try:\n            futures = []    \n            for (system_prompt, attempt_index) in tasks:\n                future = executor.submit(\n                    self._process_attempt, \n                    user_input, \n                    system_prompt, \n                    attempt_index, \n                    stop_event, \n                    deadline,\n                    problem_id\n                )\n                futures.append(future)\n    \n            for future in as_completed(futures):\n                try:\n                    result = future.result()\n                    detailed_results.append(result)\n                    if result['Answer'] is not None:\n                        valid_answers.append(result['Answer'])\n\n                    counts = Counter(valid_answers).most_common(1)\n                    if counts and counts[0][1] >= self.cfg.early_stop:\n                        stop_event.set()    \n                        for f in futures: f.cancel()\n                        break\n    \n                except Exception as exc:\n                    print(f'Future failed: {exc}')\n                    continue\n    \n        finally:\n            stop_event.set()\n            executor.shutdown(wait=True, cancel_futures=True)\n            self.problems_remaining = max(0, self.problems_remaining - 1)\n\n        if detailed_results:\n            results_dataframe = pd.DataFrame(detailed_results)\n            results_dataframe['Entropy'] = results_dataframe['Entropy'].round(3)\n            results_dataframe['Answer'] = results_dataframe['Answer'].astype('Int64')\n            \n            cols = [c for c in results_dataframe.columns if not c in self.cfg.debug_cols]\n            display(results_dataframe[cols])\n\n        problem_elapsed = time.time() - problem_start\n        problem_time = _fmt_time(problem_elapsed)\n        if not valid_answers:\n            print('\\nResult: 0\\n')\n            vote_data, final_answer = pd.DataFrame(columns=['Answer', 'Votes', 'Score']), 0\n        else:\n            vote_data, final_answer = self._select_answer(detailed_results)\n        \n        print(f\"Problem ID: {problem_id}, spent time: {problem_time}, problems_remaining = {self.problems_remaining}\")\n        self.logger.write_debug_logs(detailed_results, vote_data, problem, problem_id, problem_time)\n        return final_answer\n\n    def __del__(self):\n        if hasattr(self, 'sandbox_pool'):\n            while not self.sandbox_pool.empty():\n                try:\n                    sb = self.sandbox_pool.get_nowait()\n                    sb.close()\n                except Exception:\n                    pass","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T08:12:25.137233Z","iopub.execute_input":"2026-01-23T08:12:25.137363Z","iopub.status.idle":"2026-01-23T08:12:25.167561Z","shell.execute_reply.started":"2026-01-23T08:12:25.137349Z","shell.execute_reply":"2026-01-23T08:12:25.167183Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"_delete(\"server\")\nserver = AIMO3Server(CFG)\n\n_delete(\"solver\")\nsolver = AIMO3Solver(CFG)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T08:12:25.168059Z","iopub.execute_input":"2026-01-23T08:12:25.168185Z","iopub.status.idle":"2026-01-23T08:15:47.815417Z","shell.execute_reply.started":"2026-01-23T08:12:25.168172Z","shell.execute_reply":"2026-01-23T08:15:47.814961Z"}},"outputs":[{"name":"stdout","text":"Loading model weights from /kaggle/input/gpt-oss-120b/transformers/default/1 into OS Page Cache...\nProcessed 26 files (65.28 GB) in 65.82 seconds.\n\nWaiting for vLLM server...\nServer is ready (took 133.29 seconds).\n\nInitializing 16 persistent Jupyter kernels...\nKernels initialized in 2.91 seconds.\n\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"predict_answers = {}\n\ndef predict(id_: pl.DataFrame, question: pl.DataFrame, answer: Optional[pl.DataFrame] = None) -> pl.DataFrame:\n    global predict_answers\n    id_value = id_.item(0)\n    question_text = question.item(0)\n    gc.disable()\n    final_answer = solver.solve_problem(question_text, problem_id=str(id_value))\n    predict_answers[id_value] = final_answer\n    gc.enable()\n    gc.collect()\n    return pl.DataFrame({'id': id_value, 'answer': final_answer})\n\ninference_server = kaggle_evaluation.aimo_3_inference_server.AIMO3InferenceServer(predict)\n\ndef test():\n    global predict_answers\n\n    # test_csv = '/kaggle/input/ai-mathematical-olympiad-progress-prize-3/test.csv'\n    test_csv = '/kaggle/input/ai-mathematical-olympiad-progress-prize-3/reference.csv'\n    # test_csv = '/kaggle/input/aimo-p3-hard/test2.csv'\n    # test_csv = '/kaggle/input/aimo-p3-hard/test3.csv'\n    # test_csv = '/kaggle/input/aimo-p3-hard/p5.csv'\n    # test_csv = '/kaggle/input/aimo-p3-hard/p10.csv'\n\n    inference_server.run_local_gateway((test_csv,))\n\n    df = pd.read_csv(test_csv)\n    real_answers = dict(zip(df[\"id\"], df[\"answer\"])) if \"answer\" in df.columns else {}\n    correct_count = 0\n    total_count = 0\n    # Check accuracy if ground truth available\n    for (id, predict_answer) in predict_answers:\n        if id in real_answers:\n            total_count += 1\n            real_answer = real_answers[id]\n            is_correct = (predict_answer == real_answer)\n            if is_correct:\n                correct_count += 1\n            status = \"✅\" if is_correct else \"❌\"\n            print(f\"Problem ID: {id} -- Predict Answer: {predict_answer} | Ground Truth: {real_answer} | {status}\")\n        else:\n            print(f\"Problem ID: {id} -- Predict Answer: {predict_answer}\")\n    print(f\"📊 Running Accuracy: {correct_count}/{total_count} ({100*correct_count/total_count:.1f}%)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T08:15:47.816023Z","iopub.execute_input":"2026-01-23T08:15:47.816191Z","iopub.status.idle":"2026-01-23T08:15:47.889741Z","shell.execute_reply.started":"2026-01-23T08:15:47.816175Z","shell.execute_reply":"2026-01-23T08:15:47.889293Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n    CFG.debug = False\n    inference_server.serve()\nelse:\n    test()\n\nglobal_spent = time.time() - solver.notebook_start_time\nprint(f\"Total {len(predict_answers)} problems finished in {_fmt_time(global_spent)}!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T08:15:47.890391Z","iopub.execute_input":"2026-01-23T08:15:47.890567Z","iopub.status.idle":"2026-01-23T08:48:07.638512Z","shell.execute_reply.started":"2026-01-23T08:15:47.890547Z","shell.execute_reply":"2026-01-23T08:48:07.637857Z"}},"outputs":[{"name":"stdout","text":"\nProblem: On a blackboard, Ken starts off by writing a positive integer $n$ and then applies the following move until he first reaches $1$. Given that the number on the board is $m$, he chooses a base $b$, where $2 \\leq b \\leq m$, and considers the unique base-$b$ representation of $m$,\n\\begin{equation*}\n    m = \\sum_{k = 0}^\\infty a_k \\cdot b^k\n\\end{equation*}\nwhere $a_k$ are non-negative integers and $0 \\leq a_k < b$ for each $k$. Ken then erases $m$ on the blackboard and replaces it with $\\sum\\limits_{k = 0}^\\infty a_k$.\n\nAcross all choices of $1 \\leq n \\leq 10^{10^5}$, the largest possible number of moves Ken could make is $M$. What is the remainder when $M$ is divided by $10^{5}$?\n\nBudget: 900.00 seconds | Deadline: 1769157048.26\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"   Attempt  Response Length  Python Calls  Python Errors  Entropy  Answer  \\\n0        7             4912             4              0    0.730   32193   \n1        5             5973             5              0    0.721   32193   \n2        1             6754             1              0    0.772   32193   \n3        6             6595             9              0    0.721   32193   \n\n   Time  \n0  1:03  \n1  1:13  \n2  1:20  \n3  1:23  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Attempt</th>\n      <th>Response Length</th>\n      <th>Python Calls</th>\n      <th>Python Errors</th>\n      <th>Entropy</th>\n      <th>Answer</th>\n      <th>Time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7</td>\n      <td>4912</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0.730</td>\n      <td>32193</td>\n      <td>1:03</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5</td>\n      <td>5973</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0.721</td>\n      <td>32193</td>\n      <td>1:13</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>6754</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.772</td>\n      <td>32193</td>\n      <td>1:20</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>6595</td>\n      <td>9</td>\n      <td>0</td>\n      <td>0.721</td>\n      <td>32193</td>\n      <td>1:23</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"   Answer  Votes  Calls\n0   32193      4     19","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Answer</th>\n      <th>Votes</th>\n      <th>Calls</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>32193</td>\n      <td>4</td>\n      <td>19</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"\nFinal Result: 32193 | Votes: 4 | Calls: 19\n\nProblem ID: 42d360, spent time: 1:24, problems_remaining = 49\nDebug log written to 42d360.md\n\nProblem: Let $\\mathcal{F}$ be the set of functions $\\alpha \\colon \\mathbb{Z}\\to \\mathbb{Z}$ for which there are only finitely many $n \\in \\mathbb{Z}$ such that $\\alpha(n) \\neq 0$. \n\nFor two functions $\\alpha$ and $\\beta$ in $\\mathcal{F}$, define their product $\\alpha\\star\\beta$ to be $\\sum\\limits_{n\\in\\mathbb{Z}} \\alpha(n)\\cdot \\beta(n)$. Also, for $n\\in\\mathbb{Z}$, define a shift operator $S_n \\colon \\mathcal{F}\\to \\mathcal{F}$ by $S_n(\\alpha)(t)=\\alpha(t+n)$ for all $t \\in \\mathbb{Z}$.\n\nA function $\\alpha \\in \\mathcal{F}$ is called \\emph{shifty} if \n\\begin{itemize}\n    \\item $\\alpha(m)=0$ for all integers $m<0$ and $m>8$ and\n    \\item There exists $\\beta \\in \\mathcal{F}$ and integers $k \\neq l$ such that for all $n \\in \\mathbb{Z}$\n    \\begin{equation*}\n        S_n(\\alpha)\\star\\beta =\n        \\begin{cases}\n            1 & n \\in \\{k,l\\} \\\\\n            0 & n \\not \\in \\{k,l\\}\n        \\end{cases}\n        \\; .\n    \\end{equation*}\n\\end{itemize}\nHow many shifty functions are there in $\\mathcal{F}$?\n\nBudget: 900.00 seconds | Deadline: 1769157132.45\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"   Attempt  Response Length  Python Calls  Python Errors  Entropy  Answer  \\\n0        6            14991            10              1    0.805      44   \n1        7            15778            19              2    0.726      44   \n2        4            16273            13              1    0.738      44   \n3        2            14868            17              6    0.734      44   \n\n   Time  \n0  2:32  \n1  2:41  \n2  2:46  \n3  2:58  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Attempt</th>\n      <th>Response Length</th>\n      <th>Python Calls</th>\n      <th>Python Errors</th>\n      <th>Entropy</th>\n      <th>Answer</th>\n      <th>Time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6</td>\n      <td>14991</td>\n      <td>10</td>\n      <td>1</td>\n      <td>0.805</td>\n      <td>44</td>\n      <td>2:32</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7</td>\n      <td>15778</td>\n      <td>19</td>\n      <td>2</td>\n      <td>0.726</td>\n      <td>44</td>\n      <td>2:41</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4</td>\n      <td>16273</td>\n      <td>13</td>\n      <td>1</td>\n      <td>0.738</td>\n      <td>44</td>\n      <td>2:46</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>14868</td>\n      <td>17</td>\n      <td>6</td>\n      <td>0.734</td>\n      <td>44</td>\n      <td>2:58</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"   Answer  Votes  Calls\n0      44      4     59","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Answer</th>\n      <th>Votes</th>\n      <th>Calls</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>44</td>\n      <td>4</td>\n      <td>59</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"\nFinal Result: 44 | Votes: 4 | Calls: 59\n\nProblem ID: dd7f5e, spent time: 3:02, problems_remaining = 48\nDebug log written to dd7f5e.md\n\nProblem: Let $n \\geq 6$ be a positive integer. We call a positive integer $n$-Norwegian if it has three distinct positive divisors whose sum is equal to $n$. Let $f(n)$ denote the smallest $n$-Norwegian positive integer. Let $M=3^{2025!}$ and for a non-negative integer $c$ define \n\\begin{equation*}\n    g(c)=\\frac{1}{2025!}\\left\\lfloor \\frac{2025! f(M+c)}{M}\\right\\rfloor.\n\\end{equation*}\nWe can write \n\\begin{equation*}\n    g(0)+g(4M)+g(1848374)+g(10162574)+g(265710644)+g(44636594)=\\frac{p}{q}\n\\end{equation*}\nwhere $p$ and $q$ are coprime positive integers. What is the remainder when $p+q$ is divided by $99991$?\n\nBudget: 900.00 seconds | Deadline: 1769157314.42\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"   Attempt  Response Length  Python Calls  Python Errors  Entropy  Answer  \\\n0        4            23524            20              1    0.721      23   \n1        7            29386            37              3    0.725   52659   \n2        5            32323            47              0    0.675    <NA>   \n3        2            38766            18              1    0.735      79   \n4        6            37626            28              4    0.711       5   \n5        8            40119            67              3    0.709    8687   \n6        1            41004            68              8    0.699   85452   \n7        3            47194            87              6    0.691    8687   \n\n   Time  \n0  4:10  \n1  5:53  \n2  6:06  \n3  7:03  \n4  7:11  \n5  7:46  \n6  8:16  \n7  8:55  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Attempt</th>\n      <th>Response Length</th>\n      <th>Python Calls</th>\n      <th>Python Errors</th>\n      <th>Entropy</th>\n      <th>Answer</th>\n      <th>Time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4</td>\n      <td>23524</td>\n      <td>20</td>\n      <td>1</td>\n      <td>0.721</td>\n      <td>23</td>\n      <td>4:10</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7</td>\n      <td>29386</td>\n      <td>37</td>\n      <td>3</td>\n      <td>0.725</td>\n      <td>52659</td>\n      <td>5:53</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>32323</td>\n      <td>47</td>\n      <td>0</td>\n      <td>0.675</td>\n      <td>&lt;NA&gt;</td>\n      <td>6:06</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>38766</td>\n      <td>18</td>\n      <td>1</td>\n      <td>0.735</td>\n      <td>79</td>\n      <td>7:03</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6</td>\n      <td>37626</td>\n      <td>28</td>\n      <td>4</td>\n      <td>0.711</td>\n      <td>5</td>\n      <td>7:11</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>8</td>\n      <td>40119</td>\n      <td>67</td>\n      <td>3</td>\n      <td>0.709</td>\n      <td>8687</td>\n      <td>7:46</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1</td>\n      <td>41004</td>\n      <td>68</td>\n      <td>8</td>\n      <td>0.699</td>\n      <td>85452</td>\n      <td>8:16</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>3</td>\n      <td>47194</td>\n      <td>87</td>\n      <td>6</td>\n      <td>0.691</td>\n      <td>8687</td>\n      <td>8:55</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"   Answer  Votes  Calls\n0    8687      2    154\n1   85452      1     68\n2   52659      1     37\n3       5      1     28\n4      23      1     20\n5      79      1     18","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Answer</th>\n      <th>Votes</th>\n      <th>Calls</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>8687</td>\n      <td>2</td>\n      <td>154</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>85452</td>\n      <td>1</td>\n      <td>68</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>52659</td>\n      <td>1</td>\n      <td>37</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5</td>\n      <td>1</td>\n      <td>28</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>23</td>\n      <td>1</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>79</td>\n      <td>1</td>\n      <td>18</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"\nFinal Result: 8687 | Votes: 2 | Calls: 154\n\nProblem ID: 86e8e5, spent time: 8:55, problems_remaining = 47\nDebug log written to 86e8e5.md\n\nProblem: A $500 \\times 500$ square is divided into $k$ rectangles, each having integer side lengths. Given that no two of these rectangles have the same perimeter, the largest possible value of $k$ is $\\mathcal{K}$. What is the remainder when $k$ is divided by $10^{5}$?\n\nBudget: 900.00 seconds | Deadline: 1769157849.26\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"   Attempt  Response Length  Python Calls  Python Errors  Entropy  Answer  \\\n0        8            19852             2              0    0.949     520   \n1        7            22859             8              0    0.894     520   \n2        4            24718             8              1    0.898     520   \n3        6            26311             5              0    0.903     520   \n\n   Time  \n0  3:17  \n1  3:51  \n2  4:18  \n3  4:26  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Attempt</th>\n      <th>Response Length</th>\n      <th>Python Calls</th>\n      <th>Python Errors</th>\n      <th>Entropy</th>\n      <th>Answer</th>\n      <th>Time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>8</td>\n      <td>19852</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0.949</td>\n      <td>520</td>\n      <td>3:17</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7</td>\n      <td>22859</td>\n      <td>8</td>\n      <td>0</td>\n      <td>0.894</td>\n      <td>520</td>\n      <td>3:51</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4</td>\n      <td>24718</td>\n      <td>8</td>\n      <td>1</td>\n      <td>0.898</td>\n      <td>520</td>\n      <td>4:18</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>26311</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0.903</td>\n      <td>520</td>\n      <td>4:26</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"   Answer  Votes  Calls\n0     520      4     23","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Answer</th>\n      <th>Votes</th>\n      <th>Calls</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>520</td>\n      <td>4</td>\n      <td>23</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"\nFinal Result: 520 | Votes: 4 | Calls: 23\n\nProblem ID: a295e9, spent time: 4:27, problems_remaining = 46\nDebug log written to a295e9.md\n\nProblem: Alice and Bob are each holding some integer number of sweets. Alice says to Bob: ``If we each added the number of sweets we're holding to our (positive integer) age, my answer would be double yours. If we took the product, then my answer would be four times yours.'' Bob replies: ``Why don't you give me five of your sweets because then both our sum and product would be equal.'' What is the product of Alice and Bob's ages?\n\nBudget: 900.00 seconds | Deadline: 1769158116.54\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"   Attempt  Response Length  Python Calls  Python Errors  Entropy  Answer  \\\n0        5             1553             1              0    0.601      50   \n1        1             1977             1              0    0.569      50   \n2        8             2000             1              0    0.578      50   \n3        2             2149             2              0    0.661      50   \n\n   Time  \n0  0:15  \n1  0:19  \n2  0:19  \n3  0:20  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Attempt</th>\n      <th>Response Length</th>\n      <th>Python Calls</th>\n      <th>Python Errors</th>\n      <th>Entropy</th>\n      <th>Answer</th>\n      <th>Time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5</td>\n      <td>1553</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.601</td>\n      <td>50</td>\n      <td>0:15</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1977</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.569</td>\n      <td>50</td>\n      <td>0:19</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8</td>\n      <td>2000</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.578</td>\n      <td>50</td>\n      <td>0:19</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>2149</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0.661</td>\n      <td>50</td>\n      <td>0:20</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"   Answer  Votes  Calls\n0      50      4      5","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Answer</th>\n      <th>Votes</th>\n      <th>Calls</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>50</td>\n      <td>4</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"\nFinal Result: 50 | Votes: 4 | Calls: 5\n\nProblem ID: 92ba6a, spent time: 0:21, problems_remaining = 45\nDebug log written to 92ba6a.md\n\nProblem: Let $f \\colon \\mathbb{Z}_{\\geq 1} \\to \\mathbb{Z}_{\\geq 1}$ be a function such that for all positive integers $m$ and $n$, \n\\begin{equation*}\n    f(m) + f(n) = f(m + n + mn).\n\\end{equation*}\nAcross all functions $f$ such that $f(n) \\leq 1000$ for all $n \\leq 1000$, how many different values can $f(2024)$ take?\n\nBudget: 900.00 seconds | Deadline: 1769158137.78\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"   Attempt  Response Length  Python Calls  Python Errors  Entropy  Answer  \\\n0        7             7581             3              0    0.762     580   \n1        3             9195            11              0    0.663     580   \n2        8             8949            10              1    0.809     580   \n3        2            10988            10              0    0.769     580   \n\n   Time  \n0  1:13  \n1  1:33  \n2  1:34  \n3  1:45  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Attempt</th>\n      <th>Response Length</th>\n      <th>Python Calls</th>\n      <th>Python Errors</th>\n      <th>Entropy</th>\n      <th>Answer</th>\n      <th>Time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7</td>\n      <td>7581</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0.762</td>\n      <td>580</td>\n      <td>1:13</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>9195</td>\n      <td>11</td>\n      <td>0</td>\n      <td>0.663</td>\n      <td>580</td>\n      <td>1:33</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8</td>\n      <td>8949</td>\n      <td>10</td>\n      <td>1</td>\n      <td>0.809</td>\n      <td>580</td>\n      <td>1:34</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>10988</td>\n      <td>10</td>\n      <td>0</td>\n      <td>0.769</td>\n      <td>580</td>\n      <td>1:45</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"   Answer  Votes  Calls\n0     580      4     34","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Answer</th>\n      <th>Votes</th>\n      <th>Calls</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>580</td>\n      <td>4</td>\n      <td>34</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"\nFinal Result: 580 | Votes: 4 | Calls: 34\n\nProblem ID: 9c1c5f, spent time: 1:47, problems_remaining = 44\nDebug log written to 9c1c5f.md\n\nProblem: Define a function $f \\colon \\mathbb{Z}_{\\geq 1} \\to \\mathbb{Z}_{\\geq 1}$ by\n\\begin{equation*}\n    f(n) = \\sum_{i = 1}^n \\sum_{j = 1}^n j^{1024} \\left\\lfloor\\frac1j + \\frac{n-i}{n}\\right\\rfloor.\n\\end{equation*}\nLet $M=2 \\cdot 3 \\cdot 5 \\cdot 7 \\cdot 11 \\cdot 13$ and let $N = f{\\left(M^{15}\\right)} - f{\\left(M^{15}-1\\right)}$. Let $k$ be the largest non-negative integer such that $2^k$ divides $N$. What is the remainder when $2^k$ is divided by $5^7$?\n\nBudget: 900.00 seconds | Deadline: 1769158244.62\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"   Attempt  Response Length  Python Calls  Python Errors  Entropy  Answer  \\\n0        4             4040             3              0    0.563   32951   \n1        6             5175             6              0    0.532   32951   \n2        1             5740             5              0    0.556   32951   \n3        2             6002             3              0    0.606   32951   \n\n   Time  \n0  0:37  \n1  0:49  \n2  0:54  \n3  0:56  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Attempt</th>\n      <th>Response Length</th>\n      <th>Python Calls</th>\n      <th>Python Errors</th>\n      <th>Entropy</th>\n      <th>Answer</th>\n      <th>Time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4</td>\n      <td>4040</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0.563</td>\n      <td>32951</td>\n      <td>0:37</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>6</td>\n      <td>5175</td>\n      <td>6</td>\n      <td>0</td>\n      <td>0.532</td>\n      <td>32951</td>\n      <td>0:49</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>5740</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0.556</td>\n      <td>32951</td>\n      <td>0:54</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>6002</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0.606</td>\n      <td>32951</td>\n      <td>0:56</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"   Answer  Votes  Calls\n0   32951      4     17","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Answer</th>\n      <th>Votes</th>\n      <th>Calls</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>32951</td>\n      <td>4</td>\n      <td>17</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"\nFinal Result: 32951 | Votes: 4 | Calls: 17\n\nProblem ID: 26de63, spent time: 0:57, problems_remaining = 43\nDebug log written to 26de63.md\n\nProblem: Let $ABC$ be a triangle with $AB \\neq AC$, circumcircle $\\Omega$, and incircle $\\omega$. Let the contact points of $\\omega$ with $BC$, $CA$, and $AB$ be $D$, $E$, and $F$, respectively. Let the circumcircle of $AFE$ meet $\\Omega$ at $K$ and let the reflection of $K$ in $EF$ be $K'$. Let $N$ denote the foot of the perpendicular from $D$ to $EF$. The circle tangent to line $BN$ and passing through $B$ and $K$ intersects $BC$ again at $T \\neq B$. \n    \nLet sequence $(F_n)_{n \\geq 0}$ be defined by $F_0 = 0$, $F_1 = 1$ and for $n \\geq 2$, $F_n = F_{n-1} + F_{n-2}$. Call $ABC$ $n$\\emph{-tastic} if $BD = F_n$, $CD = F_{n+1}$, and $KNK'B$ is cyclic. Across all $n$-tastic triangles, let $a_n$ denote the maximum possible value of $\\frac{CT \\cdot NB}{BT \\cdot NE}$. Let $\\alpha$ denote the smallest real number such that for all sufficiently large $n$, $a_{2n} < \\alpha$. Given that $\\alpha = p + \\sqrt{q}$ for rationals $p$ and $q$, what is the remainder when $\\left\\lfloor p^{q^p} \\right\\rfloor$ is divided by $99991$?\n\nBudget: 900.00 seconds | Deadline: 1769158301.80\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"   Attempt  Response Length  Python Calls  Python Errors  Entropy  Answer  \\\n0        3            12492            20              3    0.548   57447   \n1        7            16301            12              1    0.538   57447   \n2        2            20695            19              3    0.496   57447   \n3        1            29532            38              5    0.640   99989   \n4        5            32560            49             10    0.577       0   \n5        8            32293            31              4    0.489   57447   \n\n   Time  \n0  2:19  \n1  2:47  \n2  3:36  \n3  5:14  \n4  5:35  \n5  6:04  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Attempt</th>\n      <th>Response Length</th>\n      <th>Python Calls</th>\n      <th>Python Errors</th>\n      <th>Entropy</th>\n      <th>Answer</th>\n      <th>Time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>12492</td>\n      <td>20</td>\n      <td>3</td>\n      <td>0.548</td>\n      <td>57447</td>\n      <td>2:19</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7</td>\n      <td>16301</td>\n      <td>12</td>\n      <td>1</td>\n      <td>0.538</td>\n      <td>57447</td>\n      <td>2:47</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>20695</td>\n      <td>19</td>\n      <td>3</td>\n      <td>0.496</td>\n      <td>57447</td>\n      <td>3:36</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>29532</td>\n      <td>38</td>\n      <td>5</td>\n      <td>0.640</td>\n      <td>99989</td>\n      <td>5:14</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>32560</td>\n      <td>49</td>\n      <td>10</td>\n      <td>0.577</td>\n      <td>0</td>\n      <td>5:35</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>8</td>\n      <td>32293</td>\n      <td>31</td>\n      <td>4</td>\n      <td>0.489</td>\n      <td>57447</td>\n      <td>6:04</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"   Answer  Votes  Calls\n0   57447      4     82\n1       0      1     49\n2   99989      1     38","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Answer</th>\n      <th>Votes</th>\n      <th>Calls</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>57447</td>\n      <td>4</td>\n      <td>82</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1</td>\n      <td>49</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>99989</td>\n      <td>1</td>\n      <td>38</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"\nFinal Result: 57447 | Votes: 4 | Calls: 82\n\nProblem ID: 641659, spent time: 6:10, problems_remaining = 42\nDebug log written to 641659.md\n\nProblem: A tournament is held with $2^{20}$ runners each of which has a different running speed. In each race, two runners compete against each other with the faster runner always winning the race. The competition consists of $20$ rounds with each runner starting with a score of $0$. In each round, the runners are paired in such a way that in each pair, both runners have the same score at the beginning of the round. The winner of each race in the $i^{\\text{th}}$ round receives $2^{20-i}$ points and the loser gets no points.\n\nAt the end of the tournament, we rank the competitors according to their scores. Let $N$ denote the number of possible orderings of the competitors at the end of the tournament. Let $k$ be the largest positive integer such that $10^k$ divides $N$. What is the remainder when $k$ is divided by $10^{5}$?\n\nBudget: 900.00 seconds | Deadline: 1769158672.27\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"   Attempt  Response Length  Python Calls  Python Errors  Entropy  Answer  \\\n0        8            11476             3              1    0.846   21818   \n1        3            11680            15              2    0.754   21818   \n2        1            12409            11              2    0.774   21818   \n3        7            12884            15              0    0.812   21818   \n\n   Time  \n0  1:54  \n1  2:05  \n2  2:05  \n3  2:09  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Attempt</th>\n      <th>Response Length</th>\n      <th>Python Calls</th>\n      <th>Python Errors</th>\n      <th>Entropy</th>\n      <th>Answer</th>\n      <th>Time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>8</td>\n      <td>11476</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0.846</td>\n      <td>21818</td>\n      <td>1:54</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>11680</td>\n      <td>15</td>\n      <td>2</td>\n      <td>0.754</td>\n      <td>21818</td>\n      <td>2:05</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>12409</td>\n      <td>11</td>\n      <td>2</td>\n      <td>0.774</td>\n      <td>21818</td>\n      <td>2:05</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7</td>\n      <td>12884</td>\n      <td>15</td>\n      <td>0</td>\n      <td>0.812</td>\n      <td>21818</td>\n      <td>2:09</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"   Answer  Votes  Calls\n0   21818      4     44","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Answer</th>\n      <th>Votes</th>\n      <th>Calls</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>21818</td>\n      <td>4</td>\n      <td>44</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"\nFinal Result: 21818 | Votes: 4 | Calls: 44\n\nProblem ID: 424e18, spent time: 2:13, problems_remaining = 41\nDebug log written to 424e18.md\n\nProblem: Let $ABC$ be an acute-angled triangle with integer side lengths and $AB<AC$. Points $D$ and $E$ lie on segments $BC$ and $AC$, respectively, such that $AD=AE=AB$. Line $DE$ intersects $AB$ at $X$. Circles $BXD$ and $CED$ intersect for the second time at $Y \\neq D$. Suppose that $Y$ lies on line $AD$. There is a unique such triangle with minimal perimeter. This triangle has side lengths $a=BC$, $b=CA$, and $c=AB$. Find the remainder when $abc$ is divided by $10^{5}$.\n\nBudget: 900.00 seconds | Deadline: 1769158805.43\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"   Attempt  Response Length  Python Calls  Python Errors  Entropy  Answer  \\\n0        8            12912            10              2    0.574     336   \n1        3            14056             9              0    0.605     336   \n2        1            15055            10              0    0.616    2688   \n3        5            16412            16              0    0.622     336   \n4        6            18599            14              1    0.586     336   \n\n   Time  \n0  2:08  \n1  2:20  \n2  2:30  \n3  2:44  \n4  3:01  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Attempt</th>\n      <th>Response Length</th>\n      <th>Python Calls</th>\n      <th>Python Errors</th>\n      <th>Entropy</th>\n      <th>Answer</th>\n      <th>Time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>8</td>\n      <td>12912</td>\n      <td>10</td>\n      <td>2</td>\n      <td>0.574</td>\n      <td>336</td>\n      <td>2:08</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>14056</td>\n      <td>9</td>\n      <td>0</td>\n      <td>0.605</td>\n      <td>336</td>\n      <td>2:20</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>15055</td>\n      <td>10</td>\n      <td>0</td>\n      <td>0.616</td>\n      <td>2688</td>\n      <td>2:30</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5</td>\n      <td>16412</td>\n      <td>16</td>\n      <td>0</td>\n      <td>0.622</td>\n      <td>336</td>\n      <td>2:44</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6</td>\n      <td>18599</td>\n      <td>14</td>\n      <td>1</td>\n      <td>0.586</td>\n      <td>336</td>\n      <td>3:01</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"   Answer  Votes  Calls\n0     336      4     49\n1    2688      1     10","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Answer</th>\n      <th>Votes</th>\n      <th>Calls</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>336</td>\n      <td>4</td>\n      <td>49</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2688</td>\n      <td>1</td>\n      <td>10</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"\nFinal Result: 336 | Votes: 4 | Calls: 49\n\nProblem ID: 0e644e, spent time: 3:02, problems_remaining = 40\nDebug log written to 0e644e.md\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_106/2830991112.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0minference_server\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mglobal_spent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotebook_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_106/362116589.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mtotal_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m# Check accuracy if ground truth available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_answer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpredict_answers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreal_answers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mtotal_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"],"ename":"ValueError","evalue":"too many values to unpack (expected 2)","output_type":"error"}],"execution_count":12},{"cell_type":"code","source":"print(predict_answers)\ntest_csv = '/kaggle/input/ai-mathematical-olympiad-progress-prize-3/reference.csv'\ndf = pd.read_csv(test_csv)\nreal_answers = dict(zip(df[\"id\"], df[\"answer\"])) if \"answer\" in df.columns else {}\ncorrect_count = 0\ntotal_count = 0\n# Check accuracy if ground truth available\nfor id in predict_answers:\n    predict_answer = predict_answers[id]\n    if id in real_answers:\n        total_count += 1\n        real_answer = real_answers[id]\n        is_correct = (predict_answer == real_answer)\n        if is_correct:\n            correct_count += 1\n        status = \"✅\" if is_correct else \"❌\"\n        print(f\"Problem ID: {id} -- Predict Answer: {predict_answer} | Ground Truth: {real_answer} | {status}\")\n    else:\n        print(f\"Problem ID: {id} -- Predict Answer: {predict_answer}\")\nprint(f\"📊 Running Accuracy: {correct_count}/{total_count} ({100*correct_count/total_count:.1f}%)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T08:59:14.701240Z","iopub.execute_input":"2026-01-23T08:59:14.701459Z","iopub.status.idle":"2026-01-23T08:59:14.716943Z","shell.execute_reply.started":"2026-01-23T08:59:14.701445Z","shell.execute_reply":"2026-01-23T08:59:14.716502Z"}},"outputs":[{"name":"stdout","text":"{'42d360': 32193, 'dd7f5e': 44, '86e8e5': 8687, 'a295e9': 520, '92ba6a': 50, '9c1c5f': 580, '26de63': 32951, '641659': 57447, '424e18': 21818, '0e644e': 336}\nProblem ID: 42d360 -- Predict Answer: 32193 | Ground Truth: 32193 | ✅\nProblem ID: dd7f5e -- Predict Answer: 44 | Ground Truth: 160 | ❌\nProblem ID: 86e8e5 -- Predict Answer: 8687 | Ground Truth: 8687 | ✅\nProblem ID: a295e9 -- Predict Answer: 520 | Ground Truth: 520 | ✅\nProblem ID: 92ba6a -- Predict Answer: 50 | Ground Truth: 50 | ✅\nProblem ID: 9c1c5f -- Predict Answer: 580 | Ground Truth: 580 | ✅\nProblem ID: 26de63 -- Predict Answer: 32951 | Ground Truth: 32951 | ✅\nProblem ID: 641659 -- Predict Answer: 57447 | Ground Truth: 57447 | ✅\nProblem ID: 424e18 -- Predict Answer: 21818 | Ground Truth: 21818 | ✅\nProblem ID: 0e644e -- Predict Answer: 336 | Ground Truth: 336 | ✅\n📊 Running Accuracy: 9/10 (90.0%)\n","output_type":"stream"}],"execution_count":14}]}